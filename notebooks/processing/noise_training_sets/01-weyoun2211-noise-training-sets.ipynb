{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## produce label-noised training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_training_set(file, noise_per_step_positives, noise_per_step_negatives, pos_steps, neg_steps):\n",
    "    \n",
    "    train_df = pd.read_json(file, compression='gzip', lines=True)\n",
    "    positives_df = train_df[train_df['label'] == 1].copy()\n",
    "    negatives_df = train_df[train_df['label'] == 0].copy()\n",
    "    \n",
    "    pos_sample_amount = int(len(positives_df)*noise_per_step_positives)\n",
    "    neg_sample_amount = int(len(negatives_df)*noise_per_step_negatives)\n",
    "    pos_noise_index = []\n",
    "    neg_noise_index = []\n",
    "    \n",
    "    for step in range(0,pos_steps):\n",
    "            positives_sample_df = positives_df.sample(n=pos_sample_amount, random_state=42)\n",
    "            pos_selected_index = list(positives_sample_df.index)\n",
    "            pos_noise_index.extend(pos_selected_index)\n",
    "            positives_df.drop(pos_selected_index, inplace=True)\n",
    "            \n",
    "    for step in range(0,neg_steps):\n",
    "            negatives_sample_df = negatives_df.sample(n=neg_sample_amount, random_state=42)\n",
    "            neg_selected_index = list(negatives_sample_df.index)\n",
    "            neg_noise_index.extend(neg_selected_index)\n",
    "            negatives_df.drop(neg_selected_index, inplace=True)\n",
    "            \n",
    "            \n",
    "    train_df.loc[pos_noise_index, 'label'] = 0\n",
    "    train_df.loc[neg_noise_index, 'label'] = 1\n",
    "    \n",
    "    file_name = os.path.basename(file)\n",
    "    new_file_name = file_name.replace('.json.gz', '_{:0.2f}_posnoise_{:0.2f}_negnoise.json.gz'.format(pos_steps*noise_per_step_positives, neg_steps*noise_per_step_negatives))\n",
    "    \n",
    "    out_path = '../../../data/interim/wdc-lspc/training-sets-noised/'\n",
    "    \n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    train_df.to_json(out_path+new_file_name, compression='gzip', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.01, 0.01, 1, 1)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.02, 0.02, 1, 1)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.03, 0.03, 1, 1)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.04, 0.04, 1, 1)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.05, 0.05, 1, 1)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.1, 0.1, 1, 1)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.1, 0.1, 2, 2)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.1, 0.1, 3, 3)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.1, 0.1, 4, 4)\n",
    "noise_training_set('../../../data/raw/wdc-lspc/training-sets/computers_train_xlarge.json.gz', 0.1, 0.1, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
