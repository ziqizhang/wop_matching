{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run magellan experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import py_entitymatching as em\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_magellan(train_set, valid_set, test_set, feature_combinations, classifiers, experiment_name, write_test_set_for_inspection=False):\n",
    "    \n",
    "    train_path = os.path.dirname(train_set)\n",
    "    train_file = os.path.basename(train_set)\n",
    "    test_path = os.path.dirname(test_set)\n",
    "    test_file =os.path.basename(test_set)\n",
    "    report_train_name = train_file.replace('.csv','')\n",
    "    report_test_name = test_file.replace('.csv','')\n",
    "\n",
    "    train_set_left = train_file.replace('pairs','left')\n",
    "    train_set_right = train_file.replace('pairs','right')\n",
    "\n",
    "    test_set_left = test_file.replace('pairs','left')\n",
    "    test_set_right = test_file.replace('pairs','right')\n",
    "    \n",
    "    os.makedirs(os.path.dirname('../../../reports/magellan/{}/'.format(experiment_name)),\n",
    "                    exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        os.remove('../../../reports/magellan/{}/{}_{}.csv'.format(experiment_name, report_train_name, report_test_name))\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    with open('../../../reports/magellan/{}/{}_{}.csv'.format(experiment_name, report_train_name, report_test_name),\"w\") as f:\n",
    "        f.write('feature#####model#####mean_train_score#####std_train_score#####mean_valid_score#####std_valid_score#####precision_test#####recall_test#####f1_test#####best_params#####train_time#####prediction_time#####feature_importance#####experiment_name#####train_set#####test_set\\n')\n",
    "\n",
    "\n",
    "    for feature_combination in feature_combinations:\n",
    "        \n",
    "        A_t = em.read_csv_metadata(train_path+'/'+train_set_left, key='mag_id')\n",
    "        B_t = em.read_csv_metadata(train_path+'/'+train_set_right, key='mag_id')\n",
    "        # Load the pre-labeled data\n",
    "        S_t = em.read_csv_metadata(train_set, \n",
    "                                 key='_id',\n",
    "                                 ltable=A_t, rtable=B_t, \n",
    "                                 fk_ltable='ltable_mag_id', fk_rtable='rtable_mag_id')\n",
    "\n",
    "        A_gs = em.read_csv_metadata(test_path+'/'+test_set_left, key='mag_id')\n",
    "        B_gs = em.read_csv_metadata(test_path+'/'+test_set_right, key='mag_id')\n",
    "        # Load the pre-labeled data\n",
    "        S_gs = em.read_csv_metadata(test_set, \n",
    "                                 key='_id',\n",
    "                                 ltable=A_gs, rtable=B_gs, \n",
    "                                 fk_ltable='ltable_mag_id', fk_rtable='rtable_mag_id')\n",
    "\n",
    "        A_t.fillna('', inplace=True)\n",
    "        A_gs.fillna('', inplace=True)\n",
    "\n",
    "        B_t.fillna('', inplace=True)\n",
    "        B_gs.fillna('', inplace=True)\n",
    "\n",
    "        S_t.fillna('', inplace=True)\n",
    "        S_gs.fillna('', inplace=True)\n",
    "\n",
    "        atypes1 = em.get_attr_types(A_t)\n",
    "        atypes2 = em.get_attr_types(B_t)\n",
    "\n",
    "        match_c = em.get_attr_corres(A_t, B_t)\n",
    "\n",
    "        match_c['corres'] = []\n",
    "\n",
    "        # select attributes to compare\n",
    "        for feature in feature_combination:\n",
    "            match_c['corres'].append((feature,feature))\n",
    "\n",
    "        tok = em.get_tokenizers_for_matching()\n",
    "        sim = em.get_sim_funs_for_matching()\n",
    "        \n",
    "        F_t = em.get_features(A_t, B_t, atypes1, atypes2, match_c, tok, sim)\n",
    "\n",
    "        H_t = em.extract_feature_vecs(S_t, \n",
    "                            feature_table=F_t, \n",
    "                            attrs_after=['label', 'pair_id'],\n",
    "                            show_progress=False)\n",
    "        H_gs = em.extract_feature_vecs(S_gs, \n",
    "                            feature_table=F_t, \n",
    "                            attrs_after='label',\n",
    "                            show_progress=False)\n",
    "\n",
    "        validation_ids_df = pd.read_csv(valid_set)\n",
    "        val_df = H_t[H_t['pair_id'].isin(validation_ids_df['pair_id'].values)]\n",
    "        train_only_df = H_t[~H_t['pair_id'].isin(validation_ids_df['pair_id'].values)]\n",
    "        \n",
    "        train_only_df = train_only_df.drop(columns='pair_id')\n",
    "        val_df = val_df.drop(columns='pair_id')\n",
    "\n",
    "        train_only_df = train_only_df.sample(frac=1, random_state=42)\n",
    "\n",
    "        pos_neg = H_t['label'].value_counts()\n",
    "        pos_neg = round(pos_neg[0] / pos_neg[1])\n",
    "\n",
    "        train_ind = []\n",
    "        val_ind = []\n",
    "\n",
    "        for i in range(len(train_only_df)-1):\n",
    "            train_ind.append(-1)\n",
    "\n",
    "        for i in range(len(val_df)-1):\n",
    "            val_ind.append(0)\n",
    "\n",
    "        ps = PredefinedSplit(test_fold=np.concatenate((train_ind,val_ind)))\n",
    "\n",
    "        train_df = pd.concat([train_only_df,val_df])\n",
    "\n",
    "\n",
    "        for k, v in classifiers.items():\n",
    "\n",
    "            classifier = v['clf']\n",
    "\n",
    "            # add pos_neg ratio to XGBoost params\n",
    "            if k == 'XGBoost':\n",
    "                v['params']['scale_pos_weight']: [1, pos_neg]\n",
    "\n",
    "            model = RandomizedSearchCV(cv=ps, estimator=classifier, param_distributions=v['params'], random_state=42, n_jobs=4, scoring='f1', n_iter=500, pre_dispatch=8, return_train_score=True)\n",
    "\n",
    "            feats_train = train_df.drop(['_id', 'ltable_mag_id', 'rtable_mag_id', 'label'], axis=1)\n",
    "            labels_train = train_df['label']\n",
    "            feats_gs = H_gs.drop(['_id', 'ltable_mag_id', 'rtable_mag_id', 'label'], axis=1)\n",
    "            labels_gs = H_gs['label']\n",
    "            \n",
    "            model.fit(feats_train, labels_train)\n",
    "\n",
    "            parameters = model.best_params_\n",
    "\n",
    "            score_names = ['mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']\n",
    "            scores = {}\n",
    "            score_string = ''\n",
    "            for name in score_names:\n",
    "                scores[name] = model.cv_results_[name][model.best_index_]\n",
    "                score_string = score_string + name + ': ' + str(scores[name]) + ' '\n",
    "\n",
    "            feature_names = list(feats_train.columns)\n",
    "\n",
    "            if k == 'LogisticRegression'or k == 'LinearSVC':\n",
    "                most_important_features = model.best_estimator_.coef_\n",
    "                word_importance = zip(feature_names, most_important_features[0].tolist())\n",
    "                word_importance = sorted(word_importance, key=lambda importance: importance[1], reverse=True)\n",
    "            if k == 'RandomForest' or k == 'DecisionTree':\n",
    "                most_important_features = model.best_estimator_.feature_importances_\n",
    "                word_importance = zip(feature_names, most_important_features.tolist())\n",
    "                word_importance =sorted(word_importance, key=lambda importance: importance[1], reverse=True)\n",
    "            if k == 'NaiveBayes':\n",
    "                word_importance = ''\n",
    "            if k == 'XGBoost':\n",
    "                most_important_features = model.best_estimator_.feature_importances_\n",
    "                word_importance = zip(feature_names, most_important_features.tolist())\n",
    "                word_importance =sorted(word_importance, key=lambda importance: importance[1], reverse=True)\n",
    "\n",
    "\n",
    "            if k == 'LogisticRegression':\n",
    "                learner = LogisticRegression(random_state=42, solver='liblinear', **parameters)\n",
    "            elif k == 'NaiveBayes':\n",
    "                learner = GaussianNB()\n",
    "            elif k == 'DecisionTree':\n",
    "                learner = DecisionTreeClassifier(random_state=42, **parameters)\n",
    "            elif k == 'LinearSVC':\n",
    "                learner = LinearSVC(random_state=42, dual=False, **parameters)\n",
    "            elif k == 'RandomForest':\n",
    "                learner = RandomForestClassifier(random_state=42, n_jobs=4, **parameters)\n",
    "            elif k == 'XGBoost':\n",
    "                learner = xgb.XGBClassifier(random_state=42, n_jobs=4, **parameters)\n",
    "            else:\n",
    "                print('Learner is not a valid option')\n",
    "                break\n",
    "\n",
    "\n",
    "            model = learner\n",
    "            feats_train = train_only_df.sample(frac=1, random_state=42)\n",
    "            feats_train = train_only_df.drop(['_id', 'ltable_mag_id', 'rtable_mag_id', 'label'], axis=1)\n",
    "            labels_train = train_only_df['label']\n",
    "\n",
    "            start = time.time()\n",
    "            model.fit(feats_train, labels_train)\n",
    "            end = time.time()\n",
    "\n",
    "            train_time = end-start\n",
    "\n",
    "            start = time.time()\n",
    "            preds_gs = model.predict(feats_gs)\n",
    "            \n",
    "            end = time.time()\n",
    "\n",
    "            pred_time = end-start           \n",
    "                                \n",
    "            gs_report = classification_report(labels_gs, preds_gs, output_dict=True)\n",
    "            \n",
    "            feature_report = '+'.join(feature_combination)\n",
    "            \n",
    "            if write_test_set_for_inspection:\n",
    "                \n",
    "                out_path = '../../../data/processed/wdc-lspc/inspection/{}/magellan/'.format(experiment_name)\n",
    "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "                \n",
    "                file_name = '_'.join([os.path.basename(train_set),os.path.basename(test_set),k,feature_report])\n",
    "                file_name = file_name.replace('.csv', '')\n",
    "                file_name += '.csv.gz'\n",
    "                \n",
    "                test_inspection_df = S_gs.copy()\n",
    "                if k == 'LinearSVC':\n",
    "                    proba_gs = model.decision_function(feats_gs).tolist()\n",
    "                else:\n",
    "                    proba_gs = model.predict_proba(feats_gs).tolist()\n",
    "                test_inspection_df['pred'] = preds_gs\n",
    "                test_inspection_df['Class Prob'] = proba_gs\n",
    "                test_inspection_df.to_csv(out_path+file_name, compression='gzip', header=True, index=False)\n",
    "            \n",
    "            with open ('../../../reports/magellan/{}/{}_{}.csv'.format(experiment_name, report_train_name, report_test_name), \"a\") as f:\n",
    "                    f.write(feature_report + '#####' + k + '#####' + str(\n",
    "                        scores['mean_train_score']) + '#####' + str(scores['std_train_score'])\n",
    "                            + '#####' + str(scores['mean_test_score']) + '#####' + str(\n",
    "                        scores['std_test_score']) + '#####' + str(gs_report['1']['precision']) + '#####' + str(\n",
    "                        gs_report['1']['recall']) + '#####' + str(gs_report['1']['f1-score'])\n",
    "                            + '#####' + str(parameters) + '#####' + str(train_time) + '#####' + str(pred_time)\n",
    "                            + '#####' + str(word_importance[0:100]) + '#####' + experiment_name + '#####'+ report_train_name+ '#####'+ report_test_name +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'NaiveBayes':  {'clf':GaussianNB(),\n",
    "                            'params':{}},\n",
    "                   'XGBoost': {'clf':xgb.XGBClassifier(random_state=42, n_jobs=4), \n",
    "                                'params':{\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "                           \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "                           \"max_depth\": [2, 4, 7, 10],\n",
    "                           \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "                           \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "                           \"reg_alpha\": [0, 0.5, 1],\n",
    "                           \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "                           \"min_child_weight\": [1, 3, 5, 7],\n",
    "                           \"n_estimators\": [100]}},\n",
    "                   'RandomForest':  {'clf':RandomForestClassifier(random_state=42, n_jobs=4), \n",
    "                                'params':{'n_estimators': [100],\n",
    "                                 'max_features': ['sqrt', 'log2', None],\n",
    "                                 'max_depth': [2,4,7,10],\n",
    "                                 'min_samples_split': [2, 5, 10, 20],\n",
    "                                 'min_samples_leaf': [1, 2, 4, 8],\n",
    "                                 'class_weight':[None, 'balanced_subsample']\n",
    "                                 }},\n",
    "                   'DecisionTree':  {'clf':DecisionTreeClassifier(random_state=42), \n",
    "                                'params':{'max_features': ['sqrt', 'log2', None],\n",
    "                                 'max_depth': [2,4,7,10],\n",
    "                                 'min_samples_split': [2, 5, 10, 20],\n",
    "                                 'min_samples_leaf': [1, 2, 4, 8],\n",
    "                                 'class_weight':[None, 'balanced']\n",
    "                                 }},\n",
    "                   'LinearSVC':  {'clf':LinearSVC(random_state=42, dual=False),\n",
    "                      'params':{'C': [0.0001 ,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                      'class_weight':[None, 'balanced']}},\n",
    "                   'LogisticRegression': {'clf':LogisticRegression(random_state=42, solver='liblinear'),\n",
    "                        'params':{'C': [0.0001 ,0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                        'class_weight':[None, 'balanced']}},\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning-curve experiment\n",
    "feature_combinations = [['title'],['title','description'],['title','description', 'brand'],['title','description', 'brand', 'specTableContent']]\n",
    "experiment_name = 'learning-curve'\n",
    "\n",
    "for file in glob.glob('../../../data/processed/wdc-lspc/magellan/learning-curve/formatted/*'):\n",
    "    if 'train_' in file and 'pairs' in file and 'metadata' not in file:\n",
    "        valid = file.replace('train_', 'valid_')\n",
    "\n",
    "        test_cat = os.path.basename(file).split('_')[0]\n",
    "        test ='../../../data/processed/wdc-lspc/magellan/learning-curve/formatted/{}_gs_magellan_pairs_formatted.csv'.format(test_cat)\n",
    "        \n",
    "        run_magellan(file, valid, test, feature_combinations, classifiers, experiment_name, write_test_set_for_inspection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy training data experiment\n",
    "feature_combinations = [['title','description','brand']]\n",
    "experiment_name = 'training-sets-noised'\n",
    "\n",
    "for file in glob.glob('../../../data/processed/wdc-lspc/magellan/training-sets-noised/formatted/*'):\n",
    "    if 'train_' in file and 'pairs' in file and 'metadata' not in file:\n",
    "        valid = file.replace('train_', 'valid_')\n",
    "\n",
    "        test_cat = os.path.basename(file).split('_')[0]\n",
    "        test ='../../../data/processed/wdc-lspc/magellan/training-sets-noised/formatted/{}_gs_magellan_pairs_formatted.csv'.format(test_cat)\n",
    "        \n",
    "        run_magellan(file, valid, test, feature_combinations, classifiers, experiment_name, write_test_set_for_inspection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
